{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import py7zr\n",
    "import os\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import welch, spectrogram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompress the .mat files if it is compressed And Load Them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following patient data and its quality:\n",
    "- `S1.mat` $\\rightarrow$ good patient data\n",
    "- `S3.mat` $\\rightarrow$ good patient data\n",
    "- `S31.mat` $\\rightarrow$ good patient data\n",
    "- `S32.mat` $\\rightarrow$ good patient data\n",
    "- `S19.mat` $\\rightarrow$ medium patient data\n",
    "- `S29.mat` $\\rightarrow$ bad patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_by_subject = np.empty((35, 64, 1500, 40, 6))\n",
    "\n",
    "for subject in range(1, 36):\n",
    "    # Path to the compressed file\n",
    "    compressed_file = f'./data/S{subject}.mat.7z'\n",
    "    mat_file = f'./data/S{subject}.mat'\n",
    "\n",
    "    # Check if the .mat file already exists\n",
    "    if os.path.exists(mat_file):\n",
    "        print(f\"Using existing file {mat_file}\")\n",
    "    # Check if the compressed file exists\n",
    "    elif os.path.exists(compressed_file):\n",
    "        # Extract the file\n",
    "        with py7zr.SevenZipFile(compressed_file, mode='r') as z:\n",
    "            z.extractall()\n",
    "        print(f\"Successfully extracted {compressed_file}\")\n",
    "    else:\n",
    "        print(f\"File {compressed_file} not found\")\n",
    "\n",
    "    eeg_data_by_subject[subject - 1] = np.array(sio.loadmat(mat_file)['data'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define useful global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_to_index = {\n",
    "    8: 0, 9: 1, 10: 2, 11: 3, 12: 4, 13: 5, 14: 6, 15: 7,\n",
    "    8.2: 8, 9.2: 9, 10.2: 10, 11.2: 11, 12.2: 12, 13.2: 13, 14.2: 14, 15.2: 15,\n",
    "    8.4: 16, 9.4: 17, 10.4: 18, 11.4: 19, 12.4: 20, 13.4: 21, 14.4: 22, 15.4: 23,\n",
    "    8.6: 24, 9.6: 25, 10.6: 26, 11.6: 27, 12.6: 28, 13.6: 29, 14.6: 30, 15.6: 31,\n",
    "    8.8: 32, 9.8: 33, 10.8: 34, 11.8: 35, 12.8: 36, 13.8: 37, 14.8: 38, 15.8: 39,\n",
    "}\n",
    "\n",
    "samples = 250 # 250 samples analyzed at once\n",
    "spacing = 4  # time between samples in ms\n",
    "fs = 250  # 250 Hz sampling rate\n",
    "\n",
    "\n",
    "time_range = np.linspace(0, samples * spacing, samples)\n",
    "freq_range = fftfreq(samples, spacing)[: samples // 2] * 1000\n",
    "default_freq_xlim = [5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 35]\n",
    "\n",
    "# Define all available channels with their corresponding indices\n",
    "relevant_channels = {\n",
    "    ### Secondary electrodes\n",
    "    \"FCz\":18,\n",
    "    \"C5\": 24,\n",
    "    \"C3\": 25,\n",
    "    \"C1\": 26,\n",
    "    \"C2\": 28,\n",
    "    \"C4\": 29,\n",
    "    \"C6\": 30,\n",
    "    \"CPz\": 37,\n",
    "    \"P7\": 43,\n",
    "    \"P5\": 44,\n",
    "    \"P3\": 45,\n",
    "    \"P1\": 46,\n",
    "    \"P2\": 48,\n",
    "    \"P4\": 49,\n",
    "    \"P6\": 50,\n",
    "    \"P8\": 51,\n",
    "\n",
    "    ### Best electrodes\n",
    "    ## Frontal\n",
    "    \"Cz\": 27,\n",
    "    \n",
    "    ## Parietal\n",
    "    \"Pz\": 47,\n",
    "    \n",
    "    ## Parieto-occipital\n",
    "    \"PO7\": 52,\n",
    "    \"PO5\": 53,\n",
    "    \"PO3\": 54,\n",
    "    \n",
    "    \"POz\": 55,\n",
    "\n",
    "    \"PO4\": 56,\n",
    "    \"PO6\": 57,\n",
    "    \"PO8\": 58,\n",
    "\n",
    "    ## Occipital\n",
    "    \"O1\": 60,\n",
    "    \"Oz\": 61,\n",
    "    \"O2\": 62,\n",
    "}\n",
    "\n",
    "# Electrode sets with number of electrodes as key and channel name/index dict as value\n",
    "channels_sets = {\n",
    "    1:  {ch: relevant_channels[ch] for ch in [\"Oz\"]},\n",
    "    4:  {ch: relevant_channels[ch] for ch in [\"POz\", \"O1\", \"Oz\", \"O2\"]},\n",
    "    8:  {ch: relevant_channels[ch] for ch in [\"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"O1\", \"Oz\", \"O2\"]},\n",
    "    9:  {ch: relevant_channels[ch] for ch in [\"Pz\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"O1\", \"Oz\", \"O2\"]},\n",
    "    12: {ch: relevant_channels[ch] for ch in [\"Cz\", \"Pz\", \"PO7\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"PO8\", \"O1\", \"Oz\", \"O2\"]},\n",
    "    14: {ch: relevant_channels[ch] for ch in [\"P3\", \"P4\", \"Cz\", \"Pz\", \"PO7\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"PO8\", \"O1\", \"Oz\", \"O2\"]},\n",
    "    16: {ch: relevant_channels[ch] for ch in [\"P3\", \"P1\", \"P2\", \"P4\", \"Cz\", \"Pz\", \"PO7\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"PO8\", \"O1\", \"Oz\", \"O2\"]},\n",
    "    18: {ch: relevant_channels[ch] for ch in [\"P5\", \"P3\", \"P1\", \"P2\", \"P4\", \"P6\", \"Cz\", \"Pz\", \"PO7\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"PO8\", \"O1\", \"Oz\", \"O2\"]},\n",
    "    20: {ch: relevant_channels[ch] for ch in [\"P7\", \"P5\", \"P3\", \"P1\", \"P2\", \"P4\", \"P6\", \"P8\", \"Cz\", \"Pz\", \"PO7\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"PO8\", \"O1\", \"Oz\", \"O2\"]},\n",
    "    22: {ch: relevant_channels[ch] for ch in [\"FCz\", \"CPz\", \"P7\", \"P5\", \"P3\", \"P1\", \"P2\", \"P4\", \"P6\", \"P8\", \"Cz\", \"Pz\", \"PO7\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"PO8\", \"O1\", \"Oz\", \"O2\"]},\n",
    "    24: {ch: relevant_channels[ch] for ch in [\"C1\", \"C2\", \"FCz\", \"CPz\", \"P7\", \"P5\", \"P3\", \"P1\", \"P2\", \"P4\", \"P6\", \"P8\", \"Cz\", \"Pz\", \"PO7\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"PO8\", \"O1\", \"Oz\", \"O2\"]},\n",
    "    26: {ch: relevant_channels[ch] for ch in [\"C3\", \"C4\", \"C1\", \"C2\", \"FCz\", \"CPz\", \"P7\", \"P5\", \"P3\", \"P1\", \"P2\", \"P4\", \"P6\", \"P8\", \"Cz\", \"Pz\", \"PO7\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"PO8\", \"O1\", \"Oz\", \"O2\"]},\n",
    "    28: {ch: relevant_channels[ch] for ch in [\"C5\", \"C6\", \"C3\", \"C4\", \"C1\", \"C2\", \"FCz\", \"CPz\", \"P7\", \"P5\", \"P3\", \"P1\", \"P2\", \"P4\", \"P6\", \"P8\", \"Cz\", \"Pz\", \"PO7\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"PO8\", \"O1\", \"Oz\", \"O2\"]},\n",
    "}\n",
    "\n",
    "selected_channels = channels_sets[4]\n",
    "\n",
    "most_relevant_channels = {\n",
    "    # \"Pz\": 47,\n",
    "    # \"POz\": 55,\n",
    "    # For most individuals\n",
    "    \"O1\": 60,\n",
    "    \"Oz\": 61,\n",
    "    \"O2\": 62,\n",
    "}\n",
    "\n",
    "# preprocessing_methods list\n",
    "preprocessing_methods = [\"CAR\", \"RPCA_L\", \"RPCA_S\", \"CAR_RPCA_L\", \"CAR_RPCA_S\"]\n",
    "\n",
    "# variables used for BCI experiments\n",
    "evoked_frequencies = [8, 10, 12, 15] # frequencies to be used for the BCI experiment (in Hz)\n",
    "default_evoked_frequency = 8\n",
    "number_of_windows = 5 # number of windows to split into the useful trial interval (1 second segments along 5 seconds per trial)\n",
    "number_of_trials = eeg_data_by_subject[0].shape[3] # number of trials to use for the BCI experiment\n",
    "bci_start_sample = 125 # the first 0.5 seconds are discarded\n",
    "bci_end_sample = 1375 # the last 0.5 seconds are discarded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "# Note: cuSignal requires separate installation\n",
    "# pip install cusignal-cu11 (for CUDA 11) or cusignal-cu12 (for CUDA 12)\n",
    "try:\n",
    "    import cusignal\n",
    "    CUSIGNAL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CUSIGNAL_AVAILABLE = False\n",
    "    print(\"cuSignal not available. Install with: pip install cusignal-cu11 or cusignal-cu12\")\n",
    "\n",
    "def spectrogram_cusignal(data, fs=250, nperseg=256, noverlap=None):\n",
    "    \"\"\"\n",
    "    GPU-accelerated spectrogram using cuSignal.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy.ndarray\n",
    "        Input signal data\n",
    "    fs : float\n",
    "        Sampling frequency\n",
    "    nperseg : int\n",
    "        Length of each segment\n",
    "    noverlap : int, optional\n",
    "        Number of points to overlap between segments\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    f : numpy.ndarray\n",
    "        Array of sample frequencies\n",
    "    t : numpy.ndarray\n",
    "        Array of segment times\n",
    "    Sxx : numpy.ndarray\n",
    "        Spectrogram of the input signal\n",
    "    \"\"\"\n",
    "    if not CUSIGNAL_AVAILABLE:\n",
    "        raise ImportError(\"cuSignal is not installed\")\n",
    "    \n",
    "    # Convert to GPU\n",
    "    data_gpu = cp.asarray(data)\n",
    "    \n",
    "    # Compute spectrogram on GPU using cuSignal\n",
    "    f_gpu, t_gpu, Sxx_gpu = cusignal.spectrogram(\n",
    "        data_gpu, \n",
    "        fs=fs, \n",
    "        nperseg=nperseg, \n",
    "        noverlap=noverlap\n",
    "    )\n",
    "    \n",
    "    # Convert back to CPU\n",
    "    f = cp.asnumpy(f_gpu)\n",
    "    t = cp.asnumpy(t_gpu)\n",
    "    Sxx = cp.asnumpy(Sxx_gpu)\n",
    "    \n",
    "    return f, t, Sxx\n",
    "\n",
    "## Notes\n",
    "# This is a CuPy (GPU-accelerated) implementation of the Robust Principal\n",
    "# Component Analysis (RPCA) algorithm.\n",
    "\n",
    "# The algorithm is based on the paper \"Robust Principal\n",
    "# Component Analysis?\" by Emmanuel J. Candès, Xiaodong Li,\n",
    "# Yi Ma, and John Wright.\n",
    "\n",
    "# RPCA returns the low-rank matrix L and the sparse matrix S\n",
    "# that best approximate the input matrix X. L captures the\n",
    "# underlying structure in X, while S captures the outliers.\n",
    "\n",
    "# This version accepts NumPy arrays, converts them to CuPy for GPU processing,\n",
    "# and returns NumPy arrays.\n",
    "\n",
    "\n",
    "def RPCA(X, lamb=None, mu=None, tolerance=None, max_iteration=None):\n",
    "    \"\"\"\n",
    "    GPU-accelerated Robust Principal Component Analysis using CuPy.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.ndarray\n",
    "        Input matrix to decompose\n",
    "    lamb : float, optional\n",
    "        Regularization parameter for sparsity\n",
    "    mu : float, optional\n",
    "        Penalty parameter for augmented Lagrangian\n",
    "    tolerance : float, optional\n",
    "        Convergence tolerance (default: 1e-9)\n",
    "    max_iteration : int, optional\n",
    "        Maximum number of iterations (default: 1000)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    L : numpy.ndarray\n",
    "        Low-rank component\n",
    "    S : numpy.ndarray\n",
    "        Sparse component\n",
    "    \"\"\"\n",
    "    # Convert input numpy array to cupy for GPU processing\n",
    "    X_gpu = cp.asarray(X)\n",
    "    \n",
    "    [m, n] = X_gpu.shape\n",
    "    unobserved = cp.isnan(X_gpu)\n",
    "    X_gpu[unobserved] = 0\n",
    "    normX = cp.linalg.norm(X_gpu, \"fro\")\n",
    "\n",
    "    # Default values for lamb, mu, tol and max_iteration\n",
    "    if lamb is None:\n",
    "        lamb = 1 / cp.sqrt(m)\n",
    "\n",
    "    if mu is None:\n",
    "        mu = 10 * lamb\n",
    "\n",
    "    if tolerance is None:\n",
    "        tolerance = 1e-9\n",
    "\n",
    "    if max_iteration is None:\n",
    "        max_iteration = 1000\n",
    "\n",
    "    # Initial solution on GPU\n",
    "    L = cp.zeros((m, n))\n",
    "    S = cp.zeros((m, n))\n",
    "    Y = cp.zeros((m, n))\n",
    "\n",
    "    for i in range(max_iteration):\n",
    "        L = Do(X_gpu - S + (1 / mu) * Y, 1 / mu)\n",
    "        S = So(X_gpu - L + (1 / mu) * Y, lamb / mu)\n",
    "\n",
    "        Z = X_gpu - L - S\n",
    "        Z[unobserved] = 0\n",
    "\n",
    "        Y = Y + mu * Z\n",
    "\n",
    "        err = cp.linalg.norm(Z, \"fro\") / normX\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            # Convert rank and cardinality to CPU for printing\n",
    "            rank_L = cp.linalg.matrix_rank(L).get()\n",
    "            card_S = cp.count_nonzero(S).get()\n",
    "            err_cpu = err.get()\n",
    "\n",
    "        if err < tolerance:\n",
    "            break\n",
    "\n",
    "    # Convert results back to numpy arrays\n",
    "    L_cpu = cp.asnumpy(L)\n",
    "    S_cpu = cp.asnumpy(S)\n",
    "    \n",
    "    return L_cpu, S_cpu\n",
    "\n",
    "\n",
    "def So(X, tau):\n",
    "    \"\"\"\n",
    "    GPU-accelerated shrinkage operator using CuPy.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tau : float or cupy array\n",
    "        The threshold value.\n",
    "    X : cupy array\n",
    "        The input array.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    cupy array\n",
    "        The result of applying the shrinkage operator to X.\n",
    "    \"\"\"\n",
    "    return cp.sign(X) * cp.maximum(cp.abs(X) - tau, 0)\n",
    "\n",
    "\n",
    "def Do(X, tau):\n",
    "    \"\"\"\n",
    "    GPU-accelerated singular value thresholding operator using CuPy.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tau : float\n",
    "        The threshold value.\n",
    "    X : cupy array\n",
    "        The input array.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    cupy array\n",
    "        The result of applying the singular value thresholding operator to X.\n",
    "    \"\"\"\n",
    "    U, S, V = cp.linalg.svd(X, full_matrices=False)\n",
    "    return cp.dot(U, cp.dot(cp.diag(cp.maximum(S - tau, 0)), V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CAR\n",
    "def apply_car_filter(eeg_data):\n",
    "    \"\"\"\n",
    "    Apply Common Average Reference (CAR) filtering to EEG data.\n",
    "    \n",
    "    CAR subtracts the average of all electrodes from each individual electrode:\n",
    "    V_i^CAR = V_i^EL - (1/n) * sum(V_j^EL) for all j electrodes\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    eeg_data : numpy.ndarray\n",
    "        Input EEG data with shape (channels, samples, frequencies, trials) or (channels, samples) or (trials, channels, samples)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    car_filtered : numpy.ndarray\n",
    "        CAR-filtered EEG data with the same shape as the input\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a copy to avoid modifying the original data\n",
    "    car_filtered = eeg_data.copy()\n",
    "    \n",
    "    # Determine if we have multiple multiple dimensions\n",
    "    if len(eeg_data.shape) == 4:  # (channels, samples, frequencies, trials)\n",
    "        n_of_trials = eeg_data.shape[3]\n",
    "        n_of_frequencies = eeg_data.shape[2]\n",
    "        # Calculate mean across channels for each trial\n",
    "        for trial in range(n_of_trials):\n",
    "            for freq in range(n_of_frequencies):\n",
    "                channel_mean = np.mean(eeg_data[:, :, freq, trial], axis=0)\n",
    "                car_filtered[:, :, freq, trial] = eeg_data[:, :, freq, trial] - channel_mean\n",
    "\n",
    "    elif len(eeg_data.shape) == 3:  # (trials, channels, samples)\n",
    "        # Calculate mean across channels for each trial\n",
    "        channel_mean = np.mean(eeg_data, axis=1, keepdims=True)\n",
    "        # Subtract mean from each channel\n",
    "        car_filtered = eeg_data - channel_mean\n",
    "\n",
    "    else:  # (channels, samples)\n",
    "        # Calculate mean across channels\n",
    "        channel_mean = np.mean(eeg_data, axis=0, keepdims=True)\n",
    "        # Subtract mean from each channel\n",
    "        car_filtered = eeg_data - channel_mean\n",
    "    \n",
    "    return car_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature extraction\n",
    "def get_label_vector(evoked_frequencies):\n",
    "    Y = np.zeros(number_of_windows * number_of_trials * len(evoked_frequencies), int)\n",
    "\n",
    "    for i, frequency in enumerate(evoked_frequencies):\n",
    "        for j in range(number_of_trials):\n",
    "            for k in range(number_of_windows):\n",
    "                Y[i * number_of_trials * number_of_windows + j * number_of_windows + k] += i\n",
    "\n",
    "    return Y\n",
    "\n",
    "def get_label_matrix(evoked_frequencies):\n",
    "    Y = np.ones((number_of_windows * number_of_trials * len(evoked_frequencies), len(evoked_frequencies)), int)\n",
    "\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if int(i / (number_of_windows * number_of_trials)) != j:\n",
    "                Y[i, j] *= -1\n",
    "\n",
    "    return Y\n",
    "\n",
    "def get_feature_matrix_from_eeg_frequency_domain(spectogram_data_by_channel_trial_and_frequency, spectogram_frequencies, evoked_frequencies, selected_channels, start_sample, end_sample, select_first_harmonic=False):\n",
    "    \n",
    "    # Building X matrix\n",
    "    number_of_frequencies = len(evoked_frequencies) * (2 if select_first_harmonic else 1)\n",
    "\n",
    "    X = np.array([np.zeros(len(selected_channels) * number_of_frequencies)])\n",
    "\n",
    "    frequency_values_to_select = evoked_frequencies\n",
    "    if select_first_harmonic: # append the first harmonic if needed\n",
    "        frequency_values_to_select = np.hstack(\n",
    "            (frequency_values_to_select, np.array(frequency_values_to_select) * 2)\n",
    "        )\n",
    "\n",
    "    for i, evoked_frequency in enumerate(evoked_frequencies):\n",
    "\n",
    "        for j in range(number_of_trials):\n",
    "\n",
    "            for k in range(number_of_windows):\n",
    "                temp = np.array([])\n",
    "\n",
    "                for channel_name in selected_channels.keys():\n",
    "\n",
    "                    channel_power_points = np.array([])\n",
    "                    for i, frequency in enumerate(spectogram_frequencies):\n",
    "                        if frequency not in frequency_values_to_select:\n",
    "                            continue\n",
    "\n",
    "                        channel_power_points = np.hstack((\n",
    "                            channel_power_points,\n",
    "                            spectogram_data_by_channel_trial_and_frequency[evoked_frequency][j][channel_name][i, k]\n",
    "                        ))\n",
    "\n",
    "                    temp = np.hstack((temp, np.array(channel_power_points)))\n",
    "                X = np.vstack((X, temp))\n",
    "\n",
    "    # Drop the first line\n",
    "    X = X[1:, :]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastSquares:\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        X_plus_bias = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1) # add bias\n",
    "        \n",
    "        self.W = np.matmul(np.linalg.pinv(X_plus_bias), Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_plus_bias = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)  # add bias\n",
    "\n",
    "        predictions = np.matmul(X_plus_bias, self.W)\n",
    "        \n",
    "        return np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spectogram\n",
    "def get_spectogram_data(eeg_data, selected_channels, evoked_frequencies, fs, start_sample, end_sample, nperseg=250):\n",
    "    \"\"\"\n",
    "    Compute the Spectogram using Welch's method for all trials and organize by evoked frequencies.\n",
    "    \n",
    "    Args:\n",
    "        eeg_data: EEG data array\n",
    "        selected_channels: Dictionary of selected channels\n",
    "        evoked_frequencies: List of evoked frequencies in Hz\n",
    "        fs: Sampling frequency\n",
    "        start_sample: Starting sample index\n",
    "        end_sample: Ending sample index\n",
    "        nperseg: Segment length for spectrogram\n",
    "        \n",
    "    Returns:\n",
    "        freqs: Frequency array\n",
    "        t: Time array\n",
    "        trial_spectrograms_by_frequency: Dictionary of evoked frequencies as keys and spectrogram data for each trial as values\n",
    "    \"\"\"\n",
    "    trial_spectrograms_by_frequency = {freq: [] for freq in evoked_frequencies}\n",
    "\n",
    "    # Get the indexes of selected channels\n",
    "    print(f\"Selected channels: {selected_channels}\")\n",
    "    print(f\"Selected channels values: {selected_channels.values()}\")\n",
    "\n",
    "    # Iterate over all trials\n",
    "    num_trials = eeg_data.shape[3]\n",
    "    for trial in range(num_trials):\n",
    "        for frequency in evoked_frequencies:\n",
    "            frequency_index = frequency_to_index[frequency]\n",
    "            # Initialize a dictionary to store spectrogram data for each channel\n",
    "            Sxx_by_channel = {}\n",
    "\n",
    "            for channel_name, channel_index in selected_channels.items():\n",
    "                channel_eeg_data = eeg_data[channel_index, start_sample:end_sample, frequency_index, trial]\n",
    "                \n",
    "                # Use spectrogram function from scipy\n",
    "                freqs, t, Sxx = spectrogram_cusignal(channel_eeg_data, fs=fs, nperseg=nperseg)\n",
    "\n",
    "                # Normalize the spectrogram\n",
    "                Sxx_normalized = Sxx / np.max(Sxx)\n",
    "\n",
    "                # Select the frequency range\n",
    "                freq_range_mask = (freqs >= 6) & (freqs <= 32)\n",
    "                freqs = freqs[freq_range_mask]\n",
    "                Sxx_normalized = Sxx_normalized[freq_range_mask, :]\n",
    "\n",
    "                Sxx_by_channel[channel_name] = Sxx_normalized\n",
    "                print(f\"Sxx_by_channel shape for trial {trial + 1}, channel {channel_name}: {Sxx_by_channel[channel_name].shape}\")\n",
    "\n",
    "            trial_spectrograms_by_frequency[frequency].append(Sxx_by_channel)\n",
    "\n",
    "    return freqs, t, trial_spectrograms_by_frequency\n",
    "\n",
    "## RPCA Spectogram\n",
    "def get_spectogram_data_rpca_filtered(eeg_data, selected_channels, evoked_frequencies, fs, start_sample, end_sample, \n",
    "                                     lambda_val, mu_val, nperseg=250, filter_type='L'):\n",
    "    \"\"\"\n",
    "    Compute the Spectrogram and apply RPCA filtering for all trials, organized by evoked frequencies.\n",
    "    \n",
    "    Args:\n",
    "        eeg_data: EEG data array\n",
    "        selected_channels: Dictionary of selected channels\n",
    "        evoked_frequencies: List of evoked frequencies in Hz\n",
    "        fs: Sampling frequency\n",
    "        start_sample: Starting sample index\n",
    "        end_sample: Ending sample index\n",
    "        lambda_val: RPCA lambda parameter\n",
    "        mu_val: RPCA mu parameter\n",
    "        nperseg: Segment length for spectrogram\n",
    "        filter_type: 'L' for low-rank component, 'S' for sparse component\n",
    "        \n",
    "    Returns:\n",
    "        freqs: Frequency array\n",
    "        t: Time array\n",
    "        trial_spectrograms_by_frequency: Dictionary of evoked frequencies as keys and RPCA-filtered components for each trial as values\n",
    "    \"\"\"\n",
    "    trial_spectrograms_by_frequency = {freq: [] for freq in evoked_frequencies}\n",
    "\n",
    "    # Get the indexes of selected channels\n",
    "    print(f\"Selected channels: {selected_channels}\")\n",
    "    print(f\"Selected channels values: {selected_channels.values()}\")\n",
    "\n",
    "    # Iterate over all trials\n",
    "    num_trials = eeg_data.shape[3]\n",
    "    for trial in range(num_trials):\n",
    "        for frequency in evoked_frequencies:\n",
    "            frequency_index = frequency_to_index[frequency]\n",
    "            # Linearize the data for channels for each trial\n",
    "            channel_linearized_data = []\n",
    "            \n",
    "            for channel_index in selected_channels.values():\n",
    "                channel_eeg_data = eeg_data[channel_index, start_sample:end_sample, frequency_index, trial]\n",
    "                \n",
    "                # Use spectrogram function from scipy\n",
    "                freqs, t, Sxx = spectrogram_cusignal(channel_eeg_data, fs=fs, nperseg=nperseg)\n",
    "\n",
    "                # Select the frequency range\n",
    "                freq_range_mask = (freqs >= 6) & (freqs <= 32)\n",
    "                freqs = freqs[freq_range_mask]\n",
    "                Sxx = Sxx[freq_range_mask, :]\n",
    "\n",
    "                channel_linearized_data.append(Sxx.flatten())\n",
    "            \n",
    "            # Stack all linearized data for the current trial\n",
    "            channel_linearized_data = np.array(channel_linearized_data)\n",
    "\n",
    "            print(f\"Channel linearized data shape for trial {trial + 1}: {channel_linearized_data.shape}\")\n",
    "            \n",
    "            # Apply RPCA filtering to the spectrogram\n",
    "            try:\n",
    "                L_spectogram, S_spectogram = RPCA(channel_linearized_data, lambda_val, mu_val, tolerance=10e-4, max_iteration=1000)\n",
    "                \n",
    "                if filter_type == 'L':\n",
    "                    Sxx_filtered = L_spectogram\n",
    "                elif filter_type == 'S':\n",
    "                    Sxx_filtered = S_spectogram\n",
    "                else:\n",
    "                    raise ValueError(\"filter_type must be 'L' or 'S'\")\n",
    "\n",
    "                # Unflatten the data\n",
    "                Sxx_filtered_by_channel = {}\n",
    "                for i, channel_name in enumerate(selected_channels.keys()):\n",
    "                    Sxx_filtered_by_channel[channel_name] = Sxx_filtered[i, :].reshape(Sxx.shape)\n",
    "                    print(f\"Sxx_filtered_by_channel shape for trial {trial + 1}: {Sxx_filtered_by_channel[channel_name].shape}\")\n",
    "\n",
    "                trial_spectrograms_by_frequency[frequency].append(Sxx_filtered_by_channel)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"RPCA filtering failed for trial {trial + 1}: {e}\")\n",
    "                print(\"Returning original spectrogram for this trial\")\n",
    "                trial_spectrograms_by_frequency[frequency].append(channel_linearized_data)\n",
    "\n",
    "    return freqs, t, trial_spectrograms_by_frequency\n",
    "\n",
    "def plot_spectrogram_comparison(eeg_data, channel_name, selected_channels, trial, frequency, fs, start_sample, end_sample,\n",
    "                                lambda_val, mu_val, nperseg=250, subject_id=None):\n",
    "    \"\"\"\n",
    "    Plot comparison of 4 spectrogram filtering methods: Original, CAR, RPCA-L, RPCA-S\n",
    "    \n",
    "    Args:\n",
    "        eeg_data: EEG data array\n",
    "        channel_name: Name of the channel to analyze\n",
    "        selected_channels: Dictionary of selected channels\n",
    "        trial: Trial number (1-indexed)\n",
    "        frequency: Frequency value in Hz\n",
    "        fs: Sampling frequency\n",
    "        start_sample: Starting sample index\n",
    "        end_sample: Ending sample index\n",
    "        lambda_val: RPCA lambda parameter\n",
    "        mu_val: RPCA mu parameter\n",
    "        nperseg: Segment length for spectrogram\n",
    "        subject_id: Subject identifier for titles\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # 1. Original spectrogram\n",
    "    freqs1, t1, trial_spectrograms1 = get_spectogram_data(\n",
    "        eeg_data, selected_channels, evoked_frequencies, fs, start_sample, end_sample, nperseg\n",
    "    )\n",
    "    im1 = axes[0].pcolormesh(t1, freqs1, trial_spectrograms1[frequency][trial - 1][channel_name])\n",
    "    axes[0].set_title(f\"Original - Trial {trial} - {channel_name}\")\n",
    "    axes[0].set_ylabel('Frequency [Hz]')\n",
    "    axes[0].set_xlabel('Time [sec]')\n",
    "    plt.colorbar(im1, ax=axes[0])\n",
    "    \n",
    "    # 2. CAR filtered spectrogram\n",
    "    freqs2, t2, trial_spectrograms2 = get_spectogram_data(\n",
    "        apply_car_filter(eeg_data), selected_channels, evoked_frequencies, fs, start_sample, end_sample, nperseg\n",
    "    )\n",
    "    im2 = axes[1].pcolormesh(t2, freqs2, trial_spectrograms2[frequency][trial - 1][channel_name])\n",
    "    axes[1].set_title(f\"CAR Filtered - Trial {trial} - {channel_name}\")\n",
    "    axes[1].set_ylabel('Frequency [Hz]')\n",
    "    axes[1].set_xlabel('Time [sec]')\n",
    "    plt.colorbar(im2, ax=axes[1])\n",
    "    \n",
    "    # 3. RPCA L component spectrogram\n",
    "    freqs3, t3, trial_spectrograms3 = get_spectogram_data_rpca_filtered(\n",
    "        eeg_data, selected_channels, evoked_frequencies, fs, start_sample, end_sample, \n",
    "        lambda_val, mu_val, nperseg, filter_type='L'\n",
    "    )\n",
    "    im3 = axes[2].pcolormesh(t3, freqs3, trial_spectrograms3[frequency][trial - 1][channel_name])\n",
    "    axes[2].set_title(f\"RPCA-L Filtered - Trial {trial} - {channel_name}\")\n",
    "    axes[2].set_ylabel('Frequency [Hz]')\n",
    "    axes[2].set_xlabel('Time [sec]')\n",
    "    plt.colorbar(im3, ax=axes[2])\n",
    "    \n",
    "    # 4. RPCA S component spectrogram\n",
    "    freqs4, t4, trial_spectrograms4 = get_spectogram_data_rpca_filtered(\n",
    "        eeg_data, selected_channels, evoked_frequencies, fs, start_sample, end_sample, \n",
    "        lambda_val, mu_val, nperseg, filter_type='S'\n",
    "    )\n",
    "    im4 = axes[3].pcolormesh(t4, freqs4, trial_spectrograms4[frequency][trial - 1][channel_name])\n",
    "    axes[3].set_title(f\"RPCA-S Filtered - Trial {trial} - {channel_name}\")\n",
    "    axes[3].set_ylabel('Frequency [Hz]')\n",
    "    axes[3].set_xlabel('Time [sec]')\n",
    "    plt.colorbar(im4, ax=axes[3])\n",
    "    \n",
    "    # 5. CAR + RPCA L component spectrogram\n",
    "    freqs5, t5, trial_spectrograms5 = get_spectogram_data_rpca_filtered(\n",
    "        apply_car_filter(eeg_data), selected_channels, evoked_frequencies, fs, start_sample, end_sample, \n",
    "        lambda_val, mu_val, nperseg, filter_type='L'\n",
    "    )\n",
    "    im5 = axes[4].pcolormesh(t5, freqs5, trial_spectrograms5[frequency][trial - 1][channel_name])\n",
    "    axes[4].set_title(f\"CAR + RPCA-L Filtered - Trial {trial} - {channel_name}\")\n",
    "    axes[4].set_ylabel('Frequency [Hz]')\n",
    "    axes[4].set_xlabel('Time [sec]')\n",
    "    plt.colorbar(im5, ax=axes[4])\n",
    "    \n",
    "    # 6. CAR + RPCA S component spectrogram\n",
    "    freqs6, t6, trial_spectrograms6 = get_spectogram_data_rpca_filtered(\n",
    "        apply_car_filter(eeg_data), selected_channels, evoked_frequencies, fs, start_sample, end_sample, \n",
    "        lambda_val, mu_val, nperseg, filter_type='S'\n",
    "    )\n",
    "    im6 = axes[5].pcolormesh(t6, freqs6, trial_spectrograms6[frequency][trial - 1][channel_name])\n",
    "    axes[5].set_title(f\"CAR + RPCA-S Filtered - Trial {trial} - {channel_name}\")\n",
    "    axes[5].set_ylabel('Frequency [Hz]')\n",
    "    axes[5].set_xlabel('Time [sec]')\n",
    "    plt.colorbar(im6, ax=axes[5])\n",
    "    \n",
    "    # Add overall title\n",
    "    subject_str = f\"Subject {subject_id}\"\n",
    "    fig.suptitle(f\"{subject_str} - Frequency {frequency} Hz - RPCA channels: {list(selected_channels.keys())} - RPCA Parameters: λ={lambda_val:.6f}, μ={mu_val:.6f}\", fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig, axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_boxplot(ls_accuracies, lda_accuracies, svm_accuracies, methods, indices, group_name, filename, selected_channels):\n",
    "    \"\"\"\n",
    "    Plots and saves a boxplot of accuracies for the given group of patients.\n",
    "\n",
    "    Args:\n",
    "        ls_accuracies (dict): Least Squares accuracies per method.\n",
    "        lda_accuracies (dict): LDA accuracies per method.\n",
    "        svm_accuracies (dict): SVM accuracies per method.\n",
    "        methods (list): List of preprocessing method names.\n",
    "        indices (list or None): Indices of patients to include (None for all).\n",
    "        group_name (str): Name of the group for the plot title.\n",
    "        filename (str): Filename to save the plot.\n",
    "        selected_channels (list): List of selected channels (for title).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    data = []\n",
    "    labels = []\n",
    "    for method in methods:\n",
    "        if indices is None:\n",
    "            data.append(ls_accuracies[method])\n",
    "            data.append(lda_accuracies[method])\n",
    "            data.append(svm_accuracies[method])\n",
    "        else:\n",
    "            data.append(np.array(ls_accuracies[method])[indices])\n",
    "            data.append(np.array(lda_accuracies[method])[indices])\n",
    "            data.append(np.array(svm_accuracies[method])[indices])\n",
    "        labels.append(f\"{method}-LS\")\n",
    "        labels.append(f\"{method}-LDA\")\n",
    "        labels.append(f\"{method}-SVM\")\n",
    "    plt.boxplot(data, labels=labels, patch_artist=True)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Distribution of Accuracies Across Subjects ({group_name}, {len(selected_channels)} channels)')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPCA Parameter Optimization for Spectrogram Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter ranges for RPCA optimization on spectrogram data\n",
    "# Using spectrogram dimensions to calculate base lambda\n",
    "channel_name = \"Oz\"\n",
    "freqs, t, Sxx = get_spectogram_data(\n",
    "    eeg_data_by_subject[0],\n",
    "    selected_channels,\n",
    "    evoked_frequencies,\n",
    "    fs=fs,\n",
    "    start_sample=bci_start_sample,\n",
    "    end_sample=bci_end_sample\n",
    ")\n",
    "\n",
    "# Base lambda calculated from spectrogram matrix dimensions\n",
    "lamb_zero_spectogram = 1 / np.sqrt(max(Sxx[default_evoked_frequency][0][channel_name].shape))\n",
    "mu_denominators = [1/10, 1, 2]\n",
    "\n",
    "lamb_values_spectogram = [20 * lamb_zero_spectogram, 5 * lamb_zero_spectogram, lamb_zero_spectogram, lamb_zero_spectogram / 1.5,\n",
    "                          lamb_zero_spectogram / 2, lamb_zero_spectogram / 2.5, lamb_zero_spectogram / 3, lamb_zero_spectogram / 3.5,\n",
    "                          lamb_zero_spectogram / 4, lamb_zero_spectogram / 5, lamb_zero_spectogram / 6, \n",
    "                          lamb_zero_spectogram / 7, lamb_zero_spectogram / 8, lamb_zero_spectogram / 9, \n",
    "                          lamb_zero_spectogram / 10, lamb_zero_spectogram / 15, lamb_zero_spectogram / 20]\n",
    "\n",
    "print(f\"Spectrogram shape: {Sxx[default_evoked_frequency][0][channel_name].shape}\")\n",
    "print(f\"Base lambda for spectrogram: {lamb_zero_spectogram:.6f}\")\n",
    "print(f\"Lambda range: {min(lamb_values_spectogram):.6f} to {max(lamb_values_spectogram):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize best lamb and mu for each preprocessing method by subject\n",
    "best_lamb_spectogram_list_by_subject = []\n",
    "best_mu_spectogram_list_by_subject = []\n",
    "max_accuracy_list_by_subject = []\n",
    "\n",
    "for subject in range(1, 36):\n",
    "    eeg_data = eeg_data_by_subject[subject - 1]\n",
    "\n",
    "    # RPCA parameter optimization for spectrogram data\n",
    "    print(f\"Testing RPCA parameters on spectrogram data for Subject {subject}...\")\n",
    "    print(f\"Testing {len(lamb_values_spectogram)} lambda values and {len(mu_denominators)} mu values\")\n",
    "\n",
    "    # Initialize best lamb and mu for each preprocessing method\n",
    "    best_lamb_spectogram_list = []\n",
    "    best_mu_spectogram_list = []\n",
    "    max_accuracy_list = []\n",
    "\n",
    "    for i, method in enumerate(preprocessing_methods):\n",
    "        if method == 'CAR':\n",
    "            best_lamb_spectogram = None\n",
    "            best_mu_spectogram = None\n",
    "            max_accuracy = None\n",
    "        else:\n",
    "            best_lamb_spectogram = lamb_zero_spectogram / 2\n",
    "            best_mu_spectogram = best_lamb_spectogram / 2\n",
    "            max_accuracy = 0\n",
    "\n",
    "        best_lamb_spectogram_list.append(best_lamb_spectogram)\n",
    "        best_mu_spectogram_list.append(best_mu_spectogram)\n",
    "        max_accuracy_list.append(max_accuracy)\n",
    "\n",
    "\n",
    "    # Create label representations for classification\n",
    "    # Y_vector: 1D array with class labels (e.g., [0, 1, 2, 0, 1, ...])\n",
    "    Y_vector = get_label_vector(evoked_frequencies)\n",
    "\n",
    "    # Y_matrix: One-hot encoded matrix representation of labels\n",
    "    # (e.g., [[1,-1,-1], [-1,1,-1], [-1,-1,1], [1,-1,-1], ...])\n",
    "    Y_matrix = get_label_matrix(evoked_frequencies)\n",
    "\n",
    "    for i, method in enumerate(preprocessing_methods):\n",
    "        if method == 'CAR':\n",
    "            continue\n",
    "\n",
    "        for j, lamb in enumerate(lamb_values_spectogram):\n",
    "            for k, mu_denominator in enumerate(mu_denominators):\n",
    "                mu = lamb / mu_denominator\n",
    "                \n",
    "                try:\n",
    "                    if method == 'RPCA_L':\n",
    "                        freqs, t, Sxx = get_spectogram_data_rpca_filtered(eeg_data, selected_channels, evoked_frequencies, fs, bci_start_sample, bci_end_sample, lamb, mu, filter_type='L')\n",
    "                        X = get_feature_matrix_from_eeg_frequency_domain(Sxx, freqs, evoked_frequencies, selected_channels, bci_start_sample, bci_end_sample, select_first_harmonic=True)\n",
    "                    elif method == 'RPCA_S':\n",
    "                        freqs, t, Sxx = get_spectogram_data_rpca_filtered(eeg_data, selected_channels, evoked_frequencies, fs, bci_start_sample, bci_end_sample, lamb, mu, filter_type='S')\n",
    "                        X = get_feature_matrix_from_eeg_frequency_domain(Sxx, freqs, evoked_frequencies, selected_channels, bci_start_sample, bci_end_sample, select_first_harmonic=True)\n",
    "                    elif method == 'CAR_RPCA_L':\n",
    "                        freqs, t, Sxx = get_spectogram_data_rpca_filtered(apply_car_filter(eeg_data), selected_channels, evoked_frequencies, fs, bci_start_sample, bci_end_sample, lamb, mu, filter_type='L')\n",
    "                        X = get_feature_matrix_from_eeg_frequency_domain(Sxx, freqs, evoked_frequencies, selected_channels, bci_start_sample, bci_end_sample, select_first_harmonic=True)\n",
    "                    elif method == 'CAR_RPCA_S':\n",
    "                        freqs, t, Sxx = get_spectogram_data_rpca_filtered(apply_car_filter(eeg_data), selected_channels, evoked_frequencies, fs, bci_start_sample, bci_end_sample, lamb, mu, filter_type='S')\n",
    "                        X = get_feature_matrix_from_eeg_frequency_domain(Sxx, freqs, evoked_frequencies, selected_channels, bci_start_sample, bci_end_sample, select_first_harmonic=True)\n",
    "\n",
    "                    # Train SVM model\n",
    "                    X_train, X_val, \\\n",
    "                    Y_vector_train, Y_vector_val, \\\n",
    "                    Y_matrix_train, Y_matrix_val = train_test_split(\n",
    "                        X,\n",
    "                        Y_vector,\n",
    "                        Y_matrix,\n",
    "                        test_size=0.2,\n",
    "                        stratify=Y_vector,\n",
    "                        random_state=42  # For reproducibility\n",
    "                    )\n",
    "                    \n",
    "                    # Train SVM model\n",
    "                    svm_model = SVC(kernel='linear')\n",
    "                    svm_model.fit(X_train, Y_vector_train)\n",
    "                    y_svm_pred = svm_model.predict(X_val)\n",
    "                    svm_acc = accuracy_score(Y_vector_val, y_svm_pred)\n",
    "\n",
    "                    print(f\"SVM accuracy: {svm_acc:.4f}\")\n",
    "                    \n",
    "                    if svm_acc > max_accuracy_list[i]:\n",
    "                        max_accuracy_list[i] = svm_acc\n",
    "                        best_lamb_spectogram_list[i] = lamb\n",
    "                        best_mu_spectogram_list[i] = mu\n",
    "                        best_lamb_spectogram_list[i] = lamb\n",
    "                        best_mu_spectogram_list[i] = mu\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "                    # Skip parameter combinations that cause numerical issues\n",
    "                    continue\n",
    "\n",
    "        print(f\"\\nBest parameters found for maximizing SVM accuracy on {method}:\")\n",
    "        print(f\"Lambda: {best_lamb_spectogram_list[i]:.6f}\")\n",
    "        print(f\"Lambda Zero: {lamb_zero_spectogram:.6f}\")\n",
    "        print(f\"Mu: {best_mu_spectogram_list[i]:.6f}\")\n",
    "        print(f\"SVM accuracy: {max_accuracy_list[i]:.4f}\")\n",
    "    \n",
    "    best_lamb_spectogram_list_by_subject.append(best_lamb_spectogram_list)\n",
    "    best_mu_spectogram_list_by_subject.append(best_mu_spectogram_list)\n",
    "    max_accuracy_list_by_subject.append(max_accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print per subject\n",
    "for subj_idx in range(len(max_accuracy_list_by_subject)):\n",
    "    print(f\"\\nSubject {subj_idx+1}:\")\n",
    "    for i, method in enumerate(preprocessing_methods):\n",
    "        print(f\"{method}: {max_accuracy_list_by_subject[subj_idx][i]:.4f}\")\n",
    "\n",
    "# Calculate mean and std across subjects for each method\n",
    "print(\"\\nMean and std across subjects:\")\n",
    "for i, method in enumerate(preprocessing_methods):\n",
    "    accs = [max_accuracy_list_by_subject[subj_idx][i] for subj_idx in range(len(max_accuracy_list_by_subject))]\n",
    "    mean_acc = np.mean(accs)\n",
    "    std_acc = np.std(accs)\n",
    "    print(f\"{method}: mean={mean_acc:.4f}, std={std_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label representations for classification\n",
    "# Y_vector: 1D array with class labels (e.g., [0, 1, 2, 0, 1, ...])\n",
    "Y_vector = get_label_vector(evoked_frequencies)\n",
    "\n",
    "# Y_matrix: One-hot encoded matrix representation of labels\n",
    "# (e.g., [[1,-1,-1], [-1,1,-1], [-1,-1,1], [1,-1,-1], ...])\n",
    "Y_matrix = get_label_matrix(evoked_frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LIST_BY_PREPROCESSING_METHOD_BY_SUBJECT = np.array([])\n",
    "\n",
    "for subject in range(1, 36):\n",
    "    eeg_data = eeg_data_by_subject[subject - 1]\n",
    "\n",
    "    X_LIST_BY_PREPROCESSING_METHOD = {\n",
    "        \"CAR\": None,\n",
    "        \"RPCA_L\": None,\n",
    "        \"RPCA_S\": None,\n",
    "        \"CAR_RPCA_L\": None,\n",
    "        \"CAR_RPCA_S\": None\n",
    "    }\n",
    "\n",
    "    for i, method in enumerate(X_LIST_BY_PREPROCESSING_METHOD.keys()):\n",
    "        if method == 'CAR':\n",
    "            continue\n",
    "        elif method == 'RPCA_L':\n",
    "            best_lamb_spectogram = best_lamb_spectogram_list[i]\n",
    "            best_mu_spectogram = best_mu_spectogram_list[i]\n",
    "        elif method == 'RPCA_S':\n",
    "            best_lamb_spectogram = best_lamb_spectogram_list[i]\n",
    "            best_mu_spectogram = best_mu_spectogram_list[i]\n",
    "        elif method == 'CAR_RPCA_L':\n",
    "            best_lamb_spectogram = best_lamb_spectogram_list[i]\n",
    "            best_mu_spectogram = best_mu_spectogram_list[i]\n",
    "        elif method == 'CAR_RPCA_S':\n",
    "            best_lamb_spectogram = best_lamb_spectogram_list[i]\n",
    "            best_mu_spectogram = best_mu_spectogram_list[i]\n",
    "\n",
    "        # Feature extraction from CAR filtered data\n",
    "        freqs, t, Sxx = get_spectogram_data(apply_car_filter(eeg_data), selected_channels, evoked_frequencies, fs, bci_start_sample, bci_end_sample)\n",
    "        X_CAR = get_feature_matrix_from_eeg_frequency_domain(Sxx, freqs, evoked_frequencies, selected_channels, bci_start_sample, bci_end_sample, select_first_harmonic=True)\n",
    "\n",
    "        # Feature extraction from RPCA low-rank component\n",
    "        freqs, t, Sxx = get_spectogram_data_rpca_filtered(eeg_data, selected_channels, evoked_frequencies, fs, bci_start_sample, bci_end_sample, best_lamb_spectogram, best_mu_spectogram, filter_type='L')\n",
    "        X_RPCA_L = get_feature_matrix_from_eeg_frequency_domain(Sxx, freqs, evoked_frequencies, selected_channels, bci_start_sample, bci_end_sample, select_first_harmonic=True)\n",
    "\n",
    "        # Feature extraction from RPCA sparse component\n",
    "        freqs, t, Sxx = get_spectogram_data_rpca_filtered(eeg_data, selected_channels, evoked_frequencies, fs, bci_start_sample, bci_end_sample, best_lamb_spectogram, best_mu_spectogram, filter_type='S')\n",
    "        X_RPCA_S = get_feature_matrix_from_eeg_frequency_domain(Sxx, freqs, evoked_frequencies, selected_channels, bci_start_sample, bci_end_sample, select_first_harmonic=True)\n",
    "\n",
    "        # Feature extraction from CAR+RPCA low-rank component\n",
    "        freqs, t, Sxx = get_spectogram_data_rpca_filtered(apply_car_filter(eeg_data), selected_channels, evoked_frequencies, fs, bci_start_sample, bci_end_sample, best_lamb_spectogram, best_mu_spectogram, filter_type='L')\n",
    "        X_CAR_RPCA_L = get_feature_matrix_from_eeg_frequency_domain(Sxx, freqs, evoked_frequencies, selected_channels, bci_start_sample, bci_end_sample, select_first_harmonic=True)\n",
    "\n",
    "        # Feature extraction from CAR+RPCA sparse component\n",
    "        freqs, t, Sxx = get_spectogram_data_rpca_filtered(apply_car_filter(eeg_data), selected_channels, evoked_frequencies, fs, bci_start_sample, bci_end_sample, best_lamb_spectogram, best_mu_spectogram, filter_type='S')\n",
    "        X_CAR_RPCA_S = get_feature_matrix_from_eeg_frequency_domain(Sxx, freqs, evoked_frequencies, selected_channels, bci_start_sample, bci_end_sample, select_first_harmonic=True)\n",
    "\n",
    "        # Make feature matrix list for all preprocessing methods\n",
    "        # MUST KEEP IN THE SAME ORDER AS THE preprocessing_methods LIST\n",
    "        X_LIST = [X_CAR, X_RPCA_L, X_RPCA_S, X_CAR_RPCA_L, X_CAR_RPCA_S]\n",
    "\n",
    "        # Store feature matrix list for each preprocessing method\n",
    "        X_LIST_BY_PREPROCESSING_METHOD[method] = X_LIST\n",
    "\n",
    "    X_LIST_BY_PREPROCESSING_METHOD_BY_SUBJECT.append(X_LIST_BY_PREPROCESSING_METHOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training_list_by_preprocessing_method_by_subject = []\n",
    "X_validation_list_by_preprocessing_method_by_subject = []\n",
    "Y_vector_training_by_preprocessing_method_by_subject = []\n",
    "Y_vector_validation_by_preprocessing_method_by_subject = []\n",
    "Y_matrix_training_by_preprocessing_method_by_subject = []\n",
    "Y_matrix_validation_by_preprocessing_method_by_subject = []\n",
    "\n",
    "for subject in range(1, 36):\n",
    "    # Split data into training (80%) and validation (20%) sets for each preprocessing method\n",
    "    # Stratify by Y_vector to ensure balanced class distribution\n",
    "    X_training_list_by_preprocessing_method = {\n",
    "        \"CAR\": None,\n",
    "        \"RPCA_L\": [],\n",
    "        \"RPCA_S\": [],\n",
    "        \"CAR_RPCA_L\": [],\n",
    "        \"CAR_RPCA_S\": []\n",
    "    }\n",
    "    X_validation_list_by_preprocessing_method = {\n",
    "        \"CAR\": None,\n",
    "        \"RPCA_L\": [],\n",
    "        \"RPCA_S\": [],\n",
    "        \"CAR_RPCA_L\": [],\n",
    "        \"CAR_RPCA_S\": []\n",
    "    }\n",
    "    Y_vector_training_by_preprocessing_method = {\n",
    "        \"CAR\": None,\n",
    "        \"RPCA_L\": [],\n",
    "        \"RPCA_S\": [],\n",
    "        \"CAR_RPCA_L\": [],\n",
    "        \"CAR_RPCA_S\": []\n",
    "    }\n",
    "    Y_matrix_training_by_preprocessing_method = {\n",
    "        \"CAR\": None,\n",
    "        \"RPCA_L\": [],\n",
    "        \"RPCA_S\": [],\n",
    "        \"CAR_RPCA_L\": [],\n",
    "        \"CAR_RPCA_S\": []\n",
    "    }\n",
    "    Y_vector_validation_by_preprocessing_method = {\n",
    "        \"CAR\": None,\n",
    "        \"RPCA_L\": [],\n",
    "        \"RPCA_S\": [],\n",
    "        \"CAR_RPCA_L\": [],\n",
    "        \"CAR_RPCA_S\": []\n",
    "    }\n",
    "    Y_matrix_validation_by_preprocessing_method = {\n",
    "        \"CAR\": None,\n",
    "        \"RPCA_L\": [],\n",
    "        \"RPCA_S\": [],\n",
    "        \"CAR_RPCA_L\": [],\n",
    "        \"CAR_RPCA_S\": []\n",
    "    }\n",
    "\n",
    "    for method in X_LIST_BY_PREPROCESSING_METHOD.keys():\n",
    "        if method == 'CAR':\n",
    "            continue\n",
    "\n",
    "        for i, X in enumerate(X_LIST_BY_PREPROCESSING_METHOD[method]):\n",
    "            X_train, X_val, \\\n",
    "            Y_vector_train, Y_vector_val, \\\n",
    "            Y_matrix_train, Y_matrix_val = train_test_split(\n",
    "                X,\n",
    "                Y_vector,\n",
    "                Y_matrix,\n",
    "                test_size=0.2,\n",
    "                stratify=Y_vector,\n",
    "                random_state=42  # For reproducibility\n",
    "            )\n",
    "            \n",
    "            X_training_list_by_preprocessing_method[method].append(X_train)\n",
    "            X_validation_list_by_preprocessing_method[method].append(X_val)\n",
    "            \n",
    "            # Store Y values only once (they're the same for all preprocessing methods)\n",
    "            if i == 0:\n",
    "                Y_vector_training, Y_vector_validation = Y_vector_train, Y_vector_val\n",
    "                Y_matrix_training, Y_matrix_validation = Y_matrix_train, Y_matrix_val\n",
    "            \n",
    "            Y_vector_training_by_preprocessing_method[method].append(Y_vector_train)\n",
    "            Y_vector_validation_by_preprocessing_method[method].append(Y_vector_val)\n",
    "            Y_matrix_training_by_preprocessing_method[method].append(Y_matrix_train)\n",
    "            Y_matrix_validation_by_preprocessing_method[method].append(Y_matrix_val)\n",
    "\n",
    "\n",
    "        print(\"\\n--- Labels ---\")\n",
    "        print(\"Y_vector Validation:\", Y_vector_validation_by_preprocessing_method[method][0].shape)\n",
    "        print(\"Y_matrix Validation:\", Y_matrix_validation_by_preprocessing_method[method][0].shape)\n",
    "        print(\"Y_vector Training:\", Y_vector_training_by_preprocessing_method[method][0].shape)\n",
    "        print(\"Y_matrix Training:\", Y_matrix_training_by_preprocessing_method[method][0].shape)\n",
    "\n",
    "    X_training_list_by_preprocessing_method_by_subject.append(X_training_list_by_preprocessing_method)\n",
    "    X_validation_list_by_preprocessing_method_by_subject.append(X_validation_list_by_preprocessing_method)\n",
    "    Y_vector_training_by_preprocessing_method_by_subject.append(Y_vector_training_by_preprocessing_method)\n",
    "    Y_vector_validation_by_preprocessing_method_by_subject.append(Y_vector_validation_by_preprocessing_method)\n",
    "    Y_matrix_training_by_preprocessing_method_by_subject.append(Y_matrix_training_by_preprocessing_method)\n",
    "    Y_matrix_validation_by_preprocessing_method_by_subject.append(Y_matrix_validation_by_preprocessing_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares_list_by_preprocessing_method = {\n",
    "    \"CAR\": None,\n",
    "    \"RPCA_L\": [],\n",
    "    \"RPCA_S\": [],\n",
    "    \"CAR_RPCA_L\": [],\n",
    "    \"CAR_RPCA_S\": []\n",
    "}\n",
    "lda_list_by_preprocessing_method = {\n",
    "    \"CAR\": None,\n",
    "    \"RPCA_L\": [],\n",
    "    \"RPCA_S\": [],\n",
    "    \"CAR_RPCA_L\": [],\n",
    "    \"CAR_RPCA_S\": []\n",
    "}\n",
    "svm_list_by_preprocessing_method = {\n",
    "    \"CAR\": None,\n",
    "    \"RPCA_L\": [],\n",
    "    \"RPCA_S\": [],\n",
    "    \"CAR_RPCA_L\": [],\n",
    "    \"CAR_RPCA_S\": []\n",
    "}\n",
    "Y_least_squares_pred_list_by_preprocessing_method = {\n",
    "    \"CAR\": None,\n",
    "    \"RPCA_L\": [],\n",
    "    \"RPCA_S\": [],\n",
    "    \"CAR_RPCA_L\": [],\n",
    "    \"CAR_RPCA_S\": []\n",
    "}\n",
    "Y_lda_pred_list_by_preprocessing_method = {\n",
    "    \"CAR\": None,\n",
    "    \"RPCA_L\": [],\n",
    "    \"RPCA_S\": [],\n",
    "    \"CAR_RPCA_L\": [],\n",
    "    \"CAR_RPCA_S\": []\n",
    "}\n",
    "Y_svm_pred_list_by_preprocessing_method = {\n",
    "    \"CAR\": None,\n",
    "    \"RPCA_L\": [],\n",
    "    \"RPCA_S\": [],\n",
    "    \"CAR_RPCA_L\": [],\n",
    "    \"CAR_RPCA_S\": []\n",
    "}\n",
    "\n",
    "for preprocessing_method in X_LIST_BY_PREPROCESSING_METHOD.keys():\n",
    "    if preprocessing_method == 'CAR':\n",
    "        continue\n",
    "    # Train models for each preprocessing method\n",
    "    least_squares_list = []\n",
    "    lda_list = []\n",
    "    svm_list = []\n",
    "    Y_least_squares_pred_list = []\n",
    "    Y_lda_pred_list = []\n",
    "    Y_svm_pred_list = []\n",
    "\n",
    "    X_training_list = X_training_list_by_preprocessing_method[preprocessing_method]\n",
    "    X_validation_list = X_validation_list_by_preprocessing_method[preprocessing_method]\n",
    "    Y_vector_training = Y_vector_training_by_preprocessing_method[preprocessing_method][0]\n",
    "    Y_vector_validation = Y_vector_validation_by_preprocessing_method[preprocessing_method][0]\n",
    "    Y_matrix_training = Y_matrix_training_by_preprocessing_method[preprocessing_method][0]\n",
    "    Y_matrix_validation = Y_matrix_validation_by_preprocessing_method[preprocessing_method][0]\n",
    "\n",
    "    for i, method in enumerate(preprocessing_methods):\n",
    "        print(f\"\\nTraining models for {method} preprocessing...\")\n",
    "        \n",
    "        # Train Least Squares model\n",
    "        ls = LeastSquares()\n",
    "        ls.fit(X_training_list[i], Y_matrix_training)\n",
    "        y_ls_pred = ls.predict(X_validation_list[i])\n",
    "        least_squares_list.append(ls)\n",
    "        Y_least_squares_pred_list.append(y_ls_pred)\n",
    "        \n",
    "        # Train LDA model\n",
    "        lda_model = LinearDiscriminantAnalysis()\n",
    "        lda_model.fit(X_training_list[i], Y_vector_training)\n",
    "        y_lda_pred = lda_model.predict(X_validation_list[i])\n",
    "        lda_list.append(lda_model)\n",
    "        Y_lda_pred_list.append(y_lda_pred)\n",
    "        \n",
    "        # Train SVM model\n",
    "        svm_model = SVC(kernel='linear')\n",
    "        svm_model.fit(X_training_list[i], Y_vector_training)\n",
    "        y_svm_pred = svm_model.predict(X_validation_list[i])\n",
    "        svm_list.append(svm_model)\n",
    "        Y_svm_pred_list.append(y_svm_pred)\n",
    "\n",
    "    least_squares_list_by_preprocessing_method[preprocessing_method] = least_squares_list\n",
    "    lda_list_by_preprocessing_method[preprocessing_method] = lda_list\n",
    "    svm_list_by_preprocessing_method[preprocessing_method] = svm_list\n",
    "    Y_least_squares_pred_list_by_preprocessing_method[preprocessing_method] = Y_least_squares_pred_list\n",
    "    Y_lda_pred_list_by_preprocessing_method[preprocessing_method] = Y_lda_pred_list\n",
    "    Y_svm_pred_list_by_preprocessing_method[preprocessing_method] = Y_svm_pred_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display accuracies for each preprocessing method\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "os.makedirs('code/results', exist_ok=True)\n",
    "\n",
    "# Initialize a pandas Series to hold accuracy DataFrames for each method, similar to a dict\n",
    "accuracies_by_preprocessing_method = pd.Series(\n",
    "    [None]*5,\n",
    "    index=[\"CAR\", \"RPCA_L\", \"RPCA_S\", \"CAR_RPCA_L\", \"CAR_RPCA_S\"],\n",
    "    dtype=object\n",
    ")\n",
    "\n",
    "for i, preprocessing_method in enumerate(X_LIST_BY_PREPROCESSING_METHOD.keys()):\n",
    "    if preprocessing_method == 'CAR':\n",
    "        continue\n",
    "\n",
    "    # Initialize lists to store accuracies\n",
    "    ls_accuracies = []\n",
    "    lda_accuracies = []\n",
    "    svm_accuracies = []\n",
    "\n",
    "    Y_vector_validation = Y_vector_validation_by_preprocessing_method[preprocessing_method][0]\n",
    "    Y_matrix_validation = Y_matrix_validation_by_preprocessing_method[preprocessing_method][0]\n",
    "    Y_least_squares_pred_list = Y_least_squares_pred_list_by_preprocessing_method[preprocessing_method]\n",
    "    Y_lda_pred_list = Y_lda_pred_list_by_preprocessing_method[preprocessing_method]\n",
    "    Y_svm_pred_list = Y_svm_pred_list_by_preprocessing_method[preprocessing_method]\n",
    "\n",
    "    # Calculate accuracies for each preprocessing method\n",
    "    for j, method in enumerate(preprocessing_methods):\n",
    "        ls_acc = accuracy_score(Y_vector_validation, Y_least_squares_pred_list[j])\n",
    "        lda_acc = accuracy_score(Y_vector_validation, Y_lda_pred_list[j])\n",
    "        svm_acc = accuracy_score(Y_vector_validation, Y_svm_pred_list[j])\n",
    "\n",
    "        ls_accuracies.append(ls_acc)\n",
    "        lda_accuracies.append(lda_acc)\n",
    "        svm_accuracies.append(svm_acc)\n",
    "\n",
    "        print(f\"\\nAccuracies for {method} preprocessing:\")\n",
    "        print(f\"LS Accuracy: {ls_acc * 100:.2f}%\")\n",
    "        print(f\"LDA Accuracy: {lda_acc * 100:.2f}%\")\n",
    "        print(f\"SVM Accuracy: {svm_acc * 100:.2f}%\")\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Maximized for Method': preprocessing_method,\n",
    "        'Preprocessing Method': preprocessing_methods,\n",
    "        'Least Squares Accuracy': [acc * 100 for acc in ls_accuracies],\n",
    "        'LDA Accuracy': [acc * 100 for acc in lda_accuracies],\n",
    "        'SVM Accuracy': [acc * 100 for acc in svm_accuracies]\n",
    "    })\n",
    "\n",
    "    accuracies_by_preprocessing_method[preprocessing_method] = results_df\n",
    "\n",
    "    # Create bar chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    x = np.arange(len(preprocessing_methods))\n",
    "    width = 0.25\n",
    "\n",
    "    bars_ls = plt.bar(x - width, ls_accuracies, width, label='Least Squares')\n",
    "    bars_lda = plt.bar(x, lda_accuracies, width, label='LDA')\n",
    "    bars_svm = plt.bar(x + width, svm_accuracies, width, label='SVM')\n",
    "\n",
    "    # Add numbers above each bar\n",
    "    for idx, bar in enumerate(bars_ls):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.01, f\"{ls_accuracies[idx]*100:.2f}%\", ha='center', va='bottom', fontsize=10)\n",
    "    for idx, bar in enumerate(bars_lda):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.01, f\"{lda_accuracies[idx]*100:.2f}%\", ha='center', va='bottom', fontsize=10)\n",
    "    for idx, bar in enumerate(bars_svm):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.01, f\"{svm_accuracies[idx]*100:.2f}%\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.xlabel('Preprocessing Method')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Subject {subject} Model Accuracy by Preprocessing Method for {len(selected_channels)} channels ({\", \".join(selected_channels.keys())})')\n",
    "    plt.suptitle(f'Maximized for Method {preprocessing_method}; Lambda: {best_lamb_spectogram_list[i]:.6f}, Mu: {best_mu_spectogram_list[i]:.6f}')\n",
    "    plt.xticks(x, preprocessing_methods, rotation=45)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))  # Set y-ticks with 0.1 step\n",
    "    plt.grid(axis='y')  # Add horizontal grid lines\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'results/accuracy_comparison_{len(selected_channels)}_maximized_for_{preprocessing_method}.png')\n",
    "    print(f\"Accuracy comparison chart saved to results/accuracy_comparison_{len(selected_channels)}_maximized_for_{preprocessing_method}.png\")\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "# Save results to CSV\n",
    "accuracies_by_preprocessing_method.to_csv(f'results/model_accuracies_maximized.csv', index=False)\n",
    "print(f\"\\nResults saved to results/model_accuracies_maximized.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
